{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efc68c3f-79ac-4298-81c3-ab84c7ae9abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e855cbd8-ee79-4f01-93ab-68513545c1b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13966fde-ea4c-45a3-9a84-d7791253c262",
   "metadata": {},
   "source": [
    "## Фиксируем seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b54b5a0c-d4a8-44bf-978b-87e00091712a",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 48\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10b0f7f4-61cc-4c55-950a-7fc4c4054352",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nerus import load_nerus\n",
    "docs = load_nerus('nerus_lenta.conllu.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adf81137-f237-4a08-ab58-7304d7f77455",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = []\n",
    "tags  = []\n",
    "\n",
    "n_docs = 3000\n",
    "\n",
    "for i, doc in enumerate(docs):\n",
    "    if i == n_docs:\n",
    "        break\n",
    "\n",
    "    for sent in doc.sents:\n",
    "        s = []\n",
    "        t = []\n",
    "        for token in sent.tokens:\n",
    "            s.append(token.text)\n",
    "            t.append(token.pos)\n",
    "\n",
    "        sents.append(s)\n",
    "        tags.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "300e5543-175e-47ea-8ce6-e2511b54e7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "padding_tokens = ['<PAD>']\n",
    "padding_tags   = ['<PAD>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "292caad7-d824-41a5-86c1-f69639849edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tags   = padding_tags   + list(set(sum(tags,  [])))\n",
    "unique_tokens = padding_tokens + list(set(sum(sents, [])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13242b74-f1ff-41a3-ae57-683e550118f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_to_idx = dict(zip(unique_tokens, np.arange(len(unique_tokens))))\n",
    "tag_to_idx   = dict(zip(unique_tags,   np.arange(len(unique_tags))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1dc78d0e-206e-4125-8fe3-77c5b115c5c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28312 7079\n"
     ]
    }
   ],
   "source": [
    "train_test_bnd = int(len(sents) * 0.8)\n",
    "\n",
    "train_sentences = sents[:train_test_bnd]\n",
    "train_tags      = tags[:train_test_bnd]\n",
    "test_sentences  = sents[train_test_bnd:]\n",
    "test_tags       = tags[train_test_bnd:]\n",
    "\n",
    "print(len(train_sentences), len(test_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ba32d93-87f8-47f2-8bb2-881267dc333e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Creating a Custom Dataset for your files\n",
    "# https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#creating-a-custom-dataset-for-your-files\n",
    "#\n",
    "class TagsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, sentences, tags, token_to_idx, tag_to_idx):\n",
    "        super().__init__()\n",
    "\n",
    "        self.sentences    = sentences\n",
    "        self.tags         = tags\n",
    "        self.token_to_idx = token_to_idx\n",
    "        self.tag_to_idx   = tag_to_idx\n",
    "\n",
    "        sent_index = []\n",
    "        tags_index = []\n",
    "\n",
    "        for sent in sentences:\n",
    "            sequence = []\n",
    "            for token in sent:\n",
    "                assert token in self.token_to_idx\n",
    "                sequence.append(self.token_to_idx[token])\n",
    "\n",
    "            sent_index.append(sequence)\n",
    "\n",
    "        for sent_tags in tags:\n",
    "            tgs = []\n",
    "            for tag in sent_tags:\n",
    "                assert tag in self.tag_to_idx\n",
    "                tgs.append(self.tag_to_idx[tag])\n",
    "\n",
    "            tags_index.append(tgs)\n",
    "\n",
    "        self.sent_index = sent_index\n",
    "        self.tags_index = tags_index\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.sent_index[idx]), torch.tensor(self.tags_index[idx])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sent_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b42a715d-d525-444f-9097-4f5d96bb6f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Provide padding for DataLoader\n",
    "#\n",
    "class Padding:\n",
    "    def __init__(self, pad_token_id, pad_tag_id):\n",
    "        self.pad_token_id = pad_token_id\n",
    "        self.pad_tag_id    = pad_tag_id\n",
    "        \n",
    "    def __call__(self, batch):\n",
    "        # Find maximum sentence length in batch\n",
    "        max_len = 0\n",
    "        for tokens, tags in batch:\n",
    "            if len(tokens) > max_len:\n",
    "                max_len = len(tokens)\n",
    "        \n",
    "        pad_sentences = []\n",
    "        pad_tags = []\n",
    "\n",
    "        for tokens, tags in batch:\n",
    "            pad_sentences.append(torch.nn.functional.pad(tokens, (0, max_len - len(tokens)), \"constant\", self.pad_token_id))\n",
    "            pad_tags.append(     torch.nn.functional.pad(tags,   (0, max_len - len(tags)),   \"constant\", self.pad_tag_id ))\n",
    "        \n",
    "        return torch.stack(pad_sentences), torch.stack(pad_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecf4861-9f67-479c-a281-e8a0f592ed51",
   "metadata": {},
   "source": [
    "## Обучение модели (код с семинара)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da2d87f8-7cf9-4049-8c50-d0901514250a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_on_batch(model, x_batch, y_batch, optimizer, loss_function):  \n",
    "    model.train()\n",
    "    model.zero_grad()\n",
    "\n",
    "    x_batch = x_batch.to(device)\n",
    "    y_batch = y_batch.to(device)\n",
    "\n",
    "    output = model(x_batch)\n",
    "    # Convert (N, L, T) to (N, T, L)\n",
    "    output = torch.transpose(output, 1, 2)\n",
    "    loss = loss_function(output, y_batch)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.cpu().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54b9017c-7281-44fa-a129-a588c1e94654",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(train_generator, model, loss_function, optimizer, callback):\n",
    "    epoch_loss = 0\n",
    "    total = 0\n",
    "\n",
    "    for it, (batch_of_x, batch_of_y) in enumerate(train_generator):\n",
    "        batch_loss = train_on_batch(\n",
    "            model, batch_of_x.to(device), batch_of_y.to(device), optimizer, loss_function)\n",
    "\n",
    "        if callback is not None:\n",
    "            callback(model, batch_loss)\n",
    "\n",
    "        epoch_loss += batch_loss * len(batch_of_x)\n",
    "        total += len(batch_of_x)\n",
    "\n",
    "    return epoch_loss / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "018290cb-01bd-41a0-9726-cac8800abe06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(count_of_epoch,\n",
    "            model,\n",
    "            dataset_loader,\n",
    "            loss_function,\n",
    "            optimizer,\n",
    "            lr=0.001,\n",
    "            callback=None):\n",
    "    optima = optimizer(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "\n",
    "    iterations = tqdm(range(count_of_epoch))\n",
    "\n",
    "    for it in iterations:\n",
    "        epoch_loss = train_epoch(\n",
    "            train_generator=dataset_loader, model=model,\n",
    "            loss_function=loss_function,\n",
    "            optimizer=optima,\n",
    "            callback=callback)\n",
    "\n",
    "        iterations.set_postfix({'train epoch loss': epoch_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80e67570-3f10-436d-86cc-db4b64dfd5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quality_of_train(dataset_loader,\n",
    "                     model,\n",
    "                     loss_function):\n",
    "    pred = []\n",
    "    real = []\n",
    "    test_loss = 0\n",
    "    total = 0\n",
    "\n",
    "    for it, (sentences, tags) in enumerate(dataset_loader):\n",
    "        sentences = sentences.to(device)\n",
    "        tags = tags.to(device)\n",
    "\n",
    "        output = model(sentences)\n",
    "\n",
    "        pred.extend(torch.argmax(output, dim=2).cpu().numpy().flatten().tolist())\n",
    "        real.extend(tags.cpu().numpy().flatten().tolist())\n",
    "\n",
    "        output = torch.transpose(output, 1, 2)\n",
    "        test_loss += loss_function(output, tags).cpu().item() * len(sentences)\n",
    "        total += len(sentences)\n",
    "\n",
    "    test_loss /= total\n",
    "\n",
    "    return test_loss, pred, real"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a4843e-d5f3-4ff5-be27-cae15594d18d",
   "metadata": {},
   "source": [
    "## Модель LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f49c9a08-7b4d-4736-aa3a-745a434d73ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(torch.nn.Module):\n",
    "    @property\n",
    "    def device(self):\n",
    "        return next(self.parameters()).device\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size, dropout, num_layers, batchnorm_threshold):\n",
    "        super(LSTM, self).__init__()\n",
    "\n",
    "        # Sequence [1, 2, 3, 123, 33, PAD ...] --> [1.23, 0.23, 0.11] (size == dim)\n",
    "        self.word_embeddings = torch.nn.Embedding(vocab_size, embedding_dim, max_norm = batchnorm_threshold)\n",
    "        \n",
    "        #\n",
    "        # Input: (N, L, H_in)\n",
    "        # N - batch size\n",
    "        # L - sequence length\n",
    "        # H_in - input size\n",
    "        #\n",
    "        # Output: (N, L, H_out)\n",
    "        # N - batch size\n",
    "        # L - sequence length\n",
    "        # H_out - hidden size\n",
    "        #\n",
    "        # See: https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n",
    "        #\n",
    "        self.lstm = torch.nn.LSTM(embedding_dim, hidden_dim, batch_first=True, dropout=dropout, num_layers=num_layers)\n",
    "        self.linear = torch.nn.Linear(hidden_dim, tagset_size)\n",
    "\n",
    "    def forward(self, x_batch):\n",
    "        embeddings = self.word_embeddings(x_batch)\n",
    "        d_n, (h_n, c_n) = self.lstm(embeddings)\n",
    "        return self.linear(d_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56aa1a4-6d9c-46b2-a095-06e80b01fcb3",
   "metadata": {},
   "source": [
    "## Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6cea83c6-b3c2-4ac7-a00f-820d4b337495",
   "metadata": {},
   "outputs": [],
   "source": [
    "class callback():\n",
    "    def __init__(self, writer, dataset_loader, loss_function, delimeter=100):\n",
    "        self.step = 0\n",
    "        self.writer = writer\n",
    "        self.delimeter = delimeter\n",
    "        self.loss_function = loss_function\n",
    "\n",
    "        self.dataset_loader = dataset_loader\n",
    "\n",
    "    def forward(self, model, loss):\n",
    "        self.step += 1\n",
    "        self.writer.add_scalar('LOSS/train', loss, self.step)\n",
    "        model.eval()\n",
    "\n",
    "        if self.step % self.delimeter == 0:\n",
    "            test_loss, pred, real = quality_of_train(dataset_loader=self.dataset_loader,\n",
    "                                                     model=model, loss_function=self.loss_function)\n",
    "            self.writer.add_scalar('LOSS/test', test_loss, self.step)\n",
    "\n",
    "            indices = (real != tag_to_idx['<PAD>']).nonzero()\n",
    "\n",
    "            real = np.array(real)[indices]\n",
    "            pred = np.array(pred)[indices]\n",
    "\n",
    "            self.writer.add_scalar('VALID/acc', accuracy_score(real, pred), self.step)\n",
    "\n",
    "    def __call__(self, model, loss):\n",
    "        return self.forward(model, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5dd65391-c7ad-49da-aaa0-0a81fc56d614",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TagsDataset(train_sentences, train_tags, token_to_idx, tag_to_idx)\n",
    "test_dataset = TagsDataset(test_sentences, test_tags, token_to_idx, tag_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "518c6f78-d87d-4081-96d7-79a62d199b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    collate_fn=Padding(\n",
    "        pad_token_id = token_to_idx['<PAD>'],\n",
    "        pad_tag_id   = tag_to_idx['<PAD>'],\n",
    "    )\n",
    ")\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    collate_fn=Padding(\n",
    "        pad_token_id = token_to_idx['<PAD>'],\n",
    "        pad_tag_id   = tag_to_idx['<PAD>'],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1edb3d2a-c933-43f5-80c1-e6d1a6faf974",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = torch.nn.CrossEntropyLoss(ignore_index=tag_to_idx['<PAD>'])\n",
    "optimizer = torch.optim.Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf6569d8-db61-49f1-81c0-44227be3ad68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0ea7031-48a9-4add-9b97-d8727f74f86e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4de40e1801e949dfa5f20ad5854e7f28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batchnorm_threshold': 1, 'dropout': 0.0, 'embedding_dim': 100, 'hidden_dim': 100, 'num_layers': 1}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bf368392d3d4902bba8af7fe363ffc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batchnorm_threshold': 1, 'dropout': 0.0, 'embedding_dim': 100, 'hidden_dim': 100, 'num_layers': 3}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61bbfba374d24ea1ae45a7958db83d40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batchnorm_threshold': 1, 'dropout': 0.0, 'embedding_dim': 100, 'hidden_dim': 300, 'num_layers': 1}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "666a23a836da447d93d242fbbf0f0bf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batchnorm_threshold': 1, 'dropout': 0.0, 'embedding_dim': 100, 'hidden_dim': 300, 'num_layers': 3}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c7811e23dce45faa24dfcd58fdeb0b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batchnorm_threshold': 1, 'dropout': 0.0, 'embedding_dim': 300, 'hidden_dim': 100, 'num_layers': 1}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "216edcede0774c01b33ac8cb90c66d48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batchnorm_threshold': 1, 'dropout': 0.0, 'embedding_dim': 300, 'hidden_dim': 100, 'num_layers': 3}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "164dc731f82d43d4a3a6770f12ef4686",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batchnorm_threshold': 1, 'dropout': 0.0, 'embedding_dim': 300, 'hidden_dim': 300, 'num_layers': 1}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd36af28abd844a392176b08c963938c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batchnorm_threshold': 1, 'dropout': 0.0, 'embedding_dim': 300, 'hidden_dim': 300, 'num_layers': 3}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2fd22e24439432d8f757843b36baa03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batchnorm_threshold': 1, 'dropout': 0.25, 'embedding_dim': 100, 'hidden_dim': 100, 'num_layers': 1}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2bb89114cd14c3d8575e86f5c11d701",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batchnorm_threshold': 1, 'dropout': 0.25, 'embedding_dim': 100, 'hidden_dim': 100, 'num_layers': 3}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08b6e912b7ef47ee97a4fbbfc0f84907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batchnorm_threshold': 1, 'dropout': 0.25, 'embedding_dim': 100, 'hidden_dim': 300, 'num_layers': 1}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4734eaf3efe4f32bfe0985fecb93621",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 23\u001b[0m\n\u001b[1;32m     19\u001b[0m writer \u001b[38;5;241m=\u001b[39m SummaryWriter(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mruns/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(params)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     21\u001b[0m call \u001b[38;5;241m=\u001b[39m callback(writer, test_dataloader, loss_function, delimeter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m300\u001b[39m)\n\u001b[0;32m---> 23\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcount_of_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 13\u001b[0m, in \u001b[0;36mtrainer\u001b[0;34m(count_of_epoch, model, dataset_loader, loss_function, optimizer, lr, callback)\u001b[0m\n\u001b[1;32m     10\u001b[0m iterations \u001b[38;5;241m=\u001b[39m tqdm(\u001b[38;5;28mrange\u001b[39m(count_of_epoch))\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m it \u001b[38;5;129;01min\u001b[39;00m iterations:\n\u001b[0;32m---> 13\u001b[0m     epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptima\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     iterations\u001b[38;5;241m.\u001b[39mset_postfix({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain epoch loss\u001b[39m\u001b[38;5;124m'\u001b[39m: epoch_loss})\n",
      "Cell \u001b[0;32mIn[14], line 6\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(train_generator, model, loss_function, optimizer, callback)\u001b[0m\n\u001b[1;32m      3\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m it, (batch_of_x, batch_of_y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_generator):\n\u001b[0;32m----> 6\u001b[0m     batch_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_on_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_of_x\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_of_y\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     10\u001b[0m         callback(model, batch_loss)\n",
      "Cell \u001b[0;32mIn[13], line 8\u001b[0m, in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, x_batch, y_batch, optimizer, loss_function)\u001b[0m\n\u001b[1;32m      5\u001b[0m x_batch \u001b[38;5;241m=\u001b[39m x_batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      6\u001b[0m y_batch \u001b[38;5;241m=\u001b[39m y_batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 8\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Convert (N, L, T) to (N, T, L)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtranspose(output, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[17], line 30\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, x_batch)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x_batch):\n\u001b[1;32m     29\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mword_embeddings(x_batch)\n\u001b[0;32m---> 30\u001b[0m     d_n, (h_n, c_n) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear(d_n)\n",
      "File \u001b[0;32m/usr/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/lib/python3.13/site-packages/torch/nn/modules/rnn.py:1124\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1121\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1124\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1125\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1127\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1128\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1129\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1130\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1132\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1133\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1134\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1136\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\n\u001b[1;32m   1137\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   1138\u001b[0m         batch_sizes,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1145\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional,\n\u001b[1;32m   1146\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "grid = ParameterGrid({\n",
    "    'num_layers' : [1, 3],\n",
    "    'embedding_dim': [100, 300],\n",
    "    'hidden_dim': [100, 300],\n",
    "    'dropout': [0.0, 0.25],\n",
    "    'batchnorm_threshold': [1, 10000],\n",
    "})\n",
    "\n",
    "for params in tqdm(grid):\n",
    "    print(str(params))\n",
    "\n",
    "    model = LSTM(\n",
    "        vocab_size  = len(token_to_idx),\n",
    "        tagset_size = len(tag_to_idx),\n",
    "        **params\n",
    "    )\n",
    "    model.to(device)\n",
    "    \n",
    "    writer = SummaryWriter(f'runs/{str(params)}')\n",
    "\n",
    "    call = callback(writer, test_dataloader, loss_function, delimeter=300)\n",
    "\n",
    "    trainer(count_of_epoch=3,\n",
    "        dataset_loader=train_dataloader,\n",
    "        model=model,\n",
    "        loss_function=loss_function,\n",
    "        optimizer=optimizer,\n",
    "        lr=0.001,\n",
    "        callback=call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3504142f-f462-4215-bee2-49a926a97433",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
